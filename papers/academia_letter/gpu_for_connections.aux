\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{bojarski_end_2016}
\citation{bojarski_explaining_2017}
\citation{thrun_learning_1995}
\citation{david_deepchess_2016}
\citation{silver_general_2018}
\citation{mnih_playing_2013}
\citation{beyeler_gpu-accelerated_2015}
\citation{yavuz_genn_2016}
\citation{stimberg_brian2genn_2020}
\citation{nageswaran_configurable_2009}
\citation{cope_spinecreator_2015}
\citation{cope_spinecreator:_2016}
\citation{james_integrating_2018}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\citation{james_integrating_2018}
\citation{cope_spineml_2014}
\citation{blelloch_prefix_1990}
\citation{harris_chapter_2010}
\citation{anaconda_inc_numba_2012}
\citation{blelloch_prefix_1990}
\citation{harris_chapter_2010}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {A} Projection patterns computed using the widening gaussian defined in the referenced code (Code A and B). Projection weights are plotted for three source neurons, whose locations are shown by large circles. This projection has an offset in the $\phi $ direction (\textbf  {\texttt  {offsetd0p}}) of -25. Other parameters: \textbf  {\texttt  {sigma\_m}}=100, \textbf  {\texttt  {W\_cut}}=0.008, \textbf  {\texttt  {fshift}}=4, \textbf  {\texttt  {sigma\_0}}=3. With these parameters, a weight table of 22,208,750 rows is generated. \textbf  {B} Log of computation time (in seconds) plotted versus $n$, the maximum possible number of weights in a projection from a population of size $d^2$ to a second population of size $d^2$. The dotted grey lines indicate $n$ for the population size shown in A. Results are shown for an AMD Threadripper 2990WX CPU (TR), an Intel Core i9-8950HK CPU (i9), an NVIDIA Quadro P5000 GPU and a GTX 1080 GPU. For small $n$, the overhead in the GPU algorithm makes it slower than the CPU algorithm. The crossover occurs at $n\approx 1.7\times 10^6$ ($d\approx 64$). \textbf  {C} Speed-up: The time taken on the CPU ($t_c$) divided by the time taken on the GPU ($t_g$) plotted vs. $n$ for two different machines (the Quadro GPU was paired with the Threadripper CPU; the 1080 with the i9). The overall speed-up exceeds one order of magnitude for populations of the size shown in A. The data for the i9/1080 is truncated because the 1080 GPU did not have enough RAM to compute patterns for $d>155$.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{f1}{{1}{3}{\textbf {A} Projection patterns computed using the widening gaussian defined in the referenced code (Code A and B). Projection weights are plotted for three source neurons, whose locations are shown by large circles. This projection has an offset in the $\phi $ direction (\code {offsetd0p}) of -25. Other parameters: \code {sigma\_m}=100, \code {W\_cut}=0.008, \code {fshift}=4, \code {sigma\_0}=3. With these parameters, a weight table of 22,208,750 rows is generated. \textbf {B} Log of computation time (in seconds) plotted versus $n$, the maximum possible number of weights in a projection from a population of size $d^2$ to a second population of size $d^2$. The dotted grey lines indicate $n$ for the population size shown in A. Results are shown for an AMD Threadripper 2990WX CPU (TR), an Intel Core i9-8950HK CPU (i9), an NVIDIA Quadro P5000 GPU and a GTX 1080 GPU. For small $n$, the overhead in the GPU algorithm makes it slower than the CPU algorithm. The crossover occurs at $n\approx 1.7\times 10^6$ ($d\approx 64$). \textbf {C} Speed-up: The time taken on the CPU ($t_c$) divided by the time taken on the GPU ($t_g$) plotted vs. $n$ for two different machines (the Quadro GPU was paired with the Threadripper CPU; the 1080 with the i9). The overall speed-up exceeds one order of magnitude for populations of the size shown in A. The data for the i9/1080 is truncated because the 1080 GPU did not have enough RAM to compute patterns for $d>155$.\relax }{figure.caption.1}{}}
\bibstyle{abbrvnotitle}
\bibdata{GPU}
\bibcite{anaconda_inc_numba_2012}{1}
\bibcite{beyeler_gpu-accelerated_2015}{2}
\bibcite{blelloch_prefix_1990}{3}
\bibcite{bojarski_end_2016}{4}
\bibcite{bojarski_explaining_2017}{5}
\bibcite{cope_spineml_2014}{6}
\bibcite{cope_spinecreator_2015}{7}
\bibcite{cope_spinecreator:_2016}{8}
\bibcite{david_deepchess_2016}{9}
\bibcite{harris_chapter_2010}{10}
\bibcite{james_integrating_2018}{11}
\bibcite{mnih_playing_2013}{12}
\bibcite{nageswaran_configurable_2009}{13}
\bibcite{silver_general_2018}{14}
\bibcite{stimberg_brian2genn_2020}{15}
\bibcite{thrun_learning_1995}{16}
\bibcite{yavuz_genn_2016}{17}
\babel@aux{english}{}
